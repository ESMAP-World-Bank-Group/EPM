{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get Wind and Solar data from IRENA Database",
   "id": "52cbbd6ef9e0c39f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:47.555414Z",
     "start_time": "2025-07-02T16:17:47.395040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timezonefinder import TimezoneFinder\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import pytz"
   ],
   "id": "2ee90bed91285872",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. User settings\n",
    "Specify the list of countries, using names used in the SPLAT Energy Supply model "
   ],
   "id": "413ed4e31a3f6216"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:48.574577Z",
     "start_time": "2025-07-02T16:17:48.571663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "countries = ['Angola', 'Burundi', 'DemocraticRepublicoftheCongo', 'Cameroon', 'Rwanda', 'CentralAfricanRepublic', 'Chad', 'Congo', 'Gabon', 'EquatorialGuinea', 'SaoTomeandPrincipe']\n",
    "\n",
    "print(f'Number of countries: {len(countries)}')"
   ],
   "id": "cddd7864b068403d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries: 11\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Load data\n",
    "When saving the data in your `input` folder, we recommend to do the following:\n",
    "- filter the excel to the countries of interest to you to reduce size\n",
    "- save the data as `.csv` instead of `.xlsx` to improve performance when loading the data\n",
    "\n",
    "For each country, clusters with the best resources for wind and solar have been identified. They are included in the data, with their corresponding latitude, longitude, theoretical capacity (MW), corresponding LCOE (taking into consideration resource quality but also distance to load and grid), and hourly profile for the year 2018.\n",
    "To obtain hourly profiles for other years, the whole open-source code should be rerun. Refer to their [Github repo](https://github.com/SPLATteam/Model-Supply-Regions-MSR-Toolset/tree/main) and to the [article](https://www.nature.com/articles/s41597-022-01786-5) for more information.\n",
    "\n",
    "To download the data, use this [Zenodo repository](https://zenodo.org/records/7014609). You should download the `.rar` file called `20220412_excel_files.rar`, and then extract it (the file weights 730MB so it's heavy). To extract `.rar` files, you can use The Unarchiver if you are working on a Mac, or 7-Zip if you are working on Windows. On Linux, use a terminal-based tool like unrar or 7z."
   ],
   "id": "4a6f8127a4f6b65e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:50.192024Z",
     "start_time": "2025-07-02T16:17:50.188736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_solarMSR = os.path.join('input', 'SolarPV_BestMSRsToCover5%CountryArea.csv')\n",
    "if not os.path.exists(file_solarMSR):\n",
    "    raise FileNotFoundError(f\"The file {file_solarMSR} does not exist. Please download the Solar PV MSR data and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_solarMSR} found. Proceeding with the analysis.\")"
   ],
   "id": "2b9ddb23aa036c08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/SolarPV_BestMSRsToCover5%CountryArea.csv found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:50.775050Z",
     "start_time": "2025-07-02T16:17:50.771160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_windMSR = os.path.join('input', 'Wind_BestMSRsToCover5%CountryArea.csv')\n",
    "if not os.path.exists(file_windMSR):\n",
    "    raise FileNotFoundError(f\"The file {file_windMSR} does not exist. Please download the Solar PV MSR data and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_windMSR} found. Proceeding with the analysis.\")"
   ],
   "id": "aa428ef5a984e8a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/Wind_BestMSRsToCover5%CountryArea.csv found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Process data\n",
    "Extract average LCOE, CF, and hourly profiles for each country.\n",
    "The code saves hourly profiles in the correct format to be used in the representative days analysis."
   ],
   "id": "34798dbbab0b3f11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:18:58.202617Z",
     "start_time": "2025-07-02T16:18:45.526536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess step to get country time zone. This step is necessary as IRENA data is expressed in local time. To account for a common time reference, those times need to be transformed into UTC time. To do so, each country time zone must be obtained\n",
    "\n",
    "# Warning: this step may take a few dozen seconds\n",
    "\n",
    "def extract_time_zone(countries, name_map):\n",
    "    \"\"\"\n",
    "    Extracts the time zone (IANA tz database name, e.g., 'Africa/Luanda') for each country in a given list.\n",
    "\n",
    "    This function takes a list of country names used in SPLAT (which may use non-standard naming conventions)\n",
    "    and a mapping (`name_map`) from SPLAT-style names to standard country names (as recognized by geocoding services).\n",
    "    It uses the `geopy` package to geocode each standard country name and `timezonefinder` to identify the time zone\n",
    "    at the country centroid.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    countries : list of str\n",
    "        List of SPLAT-style country names (e.g., ['SouthAfrica', 'DemocraticRepublicoftheCongo']).\n",
    "\n",
    "    name_map : dict\n",
    "        Dictionary mapping SPLAT-style names to standard country names\n",
    "        (e.g., {'SouthAfrica': 'South Africa'}).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping original SPLAT-style names to their IANA timezone name\n",
    "        (e.g., {'SouthAfrica': 'Africa/Johannesburg'}).\n",
    "    \"\"\"\n",
    "    standard_names = [name_map.get(c, c) for c in countries]\n",
    "\n",
    "    # Initialize timezone and geolocation tools\n",
    "    tf = TimezoneFinder()\n",
    "    geolocator = Nominatim(user_agent=\"splat_timezones\")\n",
    "\n",
    "    # Build timezone dictionary\n",
    "    country_timezones = {}\n",
    "\n",
    "    for name, std_name in zip(countries, standard_names):\n",
    "        try:\n",
    "            location = geolocator.geocode(std_name, timeout=10)\n",
    "            if location:\n",
    "                tz = tf.timezone_at(lat=location.latitude, lng=location.longitude)\n",
    "                country_timezones[name] = tz\n",
    "            else:\n",
    "                print(f\"Could not geocode: {std_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {std_name}: {e}\")\n",
    "\n",
    "        time.sleep(1)  # avoid overloading the API\n",
    "    return country_timezones\n",
    "\n",
    "# Manual correction to standard names (to help geocoder or pycountry). Transform names used in the IRENA / SPLAT database into official country names.\n",
    "# You only need to specify countries for which the SPLAT name does not correspond to official country name\n",
    "name_map = {\n",
    "    'SouthAfrica': 'South Africa',\n",
    "    'DemocraticRepublicoftheCongo': 'Democratic Republic of the Congo',\n",
    "    'UnitedRepublicofTanzania': 'Tanzania',\n",
    "    'CentralAfricanRepublic': 'Central African Republic',\n",
    "    'SaoTomeandPrincipe': 'Sao Tome and Principe'\n",
    "    # The others are fine\n",
    "}\n",
    "\n",
    "country_timezones = extract_time_zone(countries, name_map)"
   ],
   "id": "c2021b1c20682e26",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:01.028619Z",
     "start_time": "2025-07-02T16:19:01.019596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We define capex parameters used in their model\n",
    "# They use a discount rate of 10%, and lifetime of 25 years for generation, 40 years for transmission\n",
    "CAPEX_PARAMETERS = {\n",
    "    'solar': {\n",
    "        'supply_asset_capital_recovery': 0.1101681,\n",
    "        'operating_costs': 4,\n",
    "        'fixed_costs': 53500\n",
    "    },\n",
    "    'wind': {\n",
    "        'supply_asset_capital_recovery': 0.1101681,\n",
    "        'operating_costs': 0,\n",
    "        'fixed_costs': 64200\n",
    "    },\n",
    "    'grid': {\n",
    "        'supply_asset_capital_recovery': 0.102259,\n",
    "    },\n",
    "    'road': {\n",
    "        'supply_asset_capital_recovery': 0.11017,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def compute_weighted_stats(group, tech):\n",
    "    \"\"\"Weighted statistics across all relevant clusters for a given country. We use the theoretical available capacity in a given cluster as the weight.\"\"\"\n",
    "    avg_cf = (group[column_cf] * group['CapacityMW']).sum() / group['CapacityMW'].sum()  # MWh / MW\n",
    "    avg_lcoe = (group['LCOE-MWh'] * group['CapacityMW']).sum() / group['CapacityMW'].sum()  # $ / MWh\n",
    "    # For the LCOE, we use the breakdown of the LCOE into different components (generation, road and transmission), and the capital recovery rates used in the MSR model\n",
    "    cost_per_MW = ((((group['sLCOE-MWh'] - CAPEX_PARAMETERS[tech]['operating_costs'])  * (8760 * group[column_cf] / 100) - CAPEX_PARAMETERS[tech]['fixed_costs']) / CAPEX_PARAMETERS[tech]['supply_asset_capital_recovery'] + (group['tLCOE-MWh']  * (8760 * group[column_cf] / 100)) / CAPEX_PARAMETERS['grid']['supply_asset_capital_recovery'] + (group['rLCOE-MWh']  * (8760 * group[column_cf] / 100)) / CAPEX_PARAMETERS['road']['supply_asset_capital_recovery'])  * group['CapacityMW']).sum() / group['CapacityMW'].sum()  * 1e-6  # costs in m$ / MW\n",
    "    \n",
    "    return pd.Series({\n",
    "        'avg_CF': avg_cf,\n",
    "        'avg_LCOE': avg_lcoe,\n",
    "        'cost_per_MW': cost_per_MW\n",
    "    })\n",
    "\n",
    "\n",
    "# Weighted hourly profile for each country\n",
    "def weighted_hourly_profile(group):\n",
    "    weights = group['CapacityMW'].values.reshape(-1, 1)\n",
    "    hourly_data = group[hourly_cols].values\n",
    "    weighted_avg = (hourly_data * weights).sum(axis=0) / weights.sum()\n",
    "    return pd.Series(weighted_avg, index=hourly_cols)\n",
    "\n",
    "def convert_to_utc(row, country_timezones):\n",
    "    \"\"\"\n",
    "    Converts a local timestamp to UTC based on the country's time zone.\n",
    "\n",
    "    This function is designed to be used within a pandas `.apply()` call\n",
    "    to convert a 'timestamp' column (assumed local time) into UTC, using\n",
    "    a dictionary that maps each country name to its IANA time zone string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pd.Series\n",
    "        A row from the DataFrame containing at least 'CtryName' and 'timestamp'.\n",
    "    country_timezones : dict\n",
    "        Dictionary mapping country names (as in 'CtryName') to their IANA time zone names,\n",
    "        e.g., {'SouthAfrica': 'Africa/Johannesburg'}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datetime\n",
    "        The timestamp converted to UTC timezone.\n",
    "    \"\"\"\n",
    "    ctry = row['CtryName']\n",
    "    local_zone = pytz.timezone(country_timezones[ctry])\n",
    "    local_time = local_zone.localize(row['timestamp'], is_dst=None)\n",
    "    return local_time.astimezone(pytz.utc)\n"
   ],
   "id": "10acb50231f6a135",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:19.016678Z",
     "start_time": "2025-07-02T16:19:01.645416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cf_lcoe_stats = {}\n",
    "hourly_profiles = {}\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    if tech == 'wind':\n",
    "        file = file_windMSR\n",
    "        column_cf = 'CF100m'\n",
    "    else:\n",
    "        file = file_solarMSR\n",
    "        column_cf = 'CF'\n",
    "\n",
    "    # Select relevant columns\n",
    "    meta_cols = ['CtryName', 'CapacityMW', column_cf, 'sLCOE-MWh', 'tLCOE-MWh', 'rLCOE-MWh', 'LCOE-MWh']\n",
    "    hourly_cols = [f'H{i}' for i in range(1, 8761)]  # if needed\n",
    "\n",
    "    # Combine what you need\n",
    "    use_columns = meta_cols + hourly_cols  # or just meta_cols to start\n",
    "\n",
    "    data_MSR_stats = pd.read_csv(file, usecols=use_columns, header=0)\n",
    "    data_MSR_stats = data_MSR_stats[data_MSR_stats['CtryName'].isin([c for c in countries])]\n",
    "\n",
    "    cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
    "\n",
    "    data_MSR_hourlyprofile = data_MSR_stats.set_index(['CtryName', 'CapacityMW'])[hourly_cols].reset_index()\n",
    "    hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
    "\n",
    "    # Saving data in good format for representative days analysis\n",
    "    date_index = pd.date_range(start='2023-01-01', periods=8760, freq='h')  # 2023 is a non-leap year\n",
    "\n",
    "    df_long = hourly_profiles[tech].melt(id_vars='CtryName', var_name='Hour', value_name='value')\n",
    "\n",
    "    # Convert 'H1', ..., 'H8760' to integer hour index\n",
    "    df_long['hour_index'] = df_long['Hour'].str.extract('H(\\d+)').astype(int) - 1  # zero-based index\n",
    "\n",
    "    df_long['timestamp'] = df_long['hour_index'].map(lambda i: date_index[i])\n",
    "\n",
    "    # Convert local time to UTC\n",
    "    df_long['CtryName'] = df_long['CtryName'].astype(str)  # just in case\n",
    "    df_long['timestamp_utc'] = df_long.apply(lambda row: convert_to_utc(row, country_timezones), axis=1)\n",
    "\n",
    "    # Create season, day and hours\n",
    "    df_long['season'] = df_long['timestamp_utc'].dt.month\n",
    "    df_long['day'] = df_long['timestamp_utc'].dt.day\n",
    "    df_long['hour'] = df_long['timestamp_utc'].dt.hour\n",
    "\n",
    "    # Step 5: Rename and index\n",
    "    df_long = df_long.rename(columns={'CtryName': 'zone'})\n",
    "    df_final = df_long.set_index(['zone', 'season', 'day', 'hour'])['value']\n",
    "    df_final = df_final.to_frame().rename(columns={'value': 2018}).sort_values(by=['season', 'day', 'hour'])\n",
    "\n",
    "    df_final.to_csv(os.path.join('output', f'data_SAPP_{tech}.csv'), index=True)"
   ],
   "id": "b26efb45d80c4e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:28: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_index = pd.date_range(start='2023-01-01', periods=8760, freq='H')  # 2023 is a non-leap year\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:28: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_index = pd.date_range(start='2023-01-01', periods=8760, freq='H')  # 2023 is a non-leap year\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Visualization data",
   "id": "dd073cd811ad0107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Make heatmap",
   "id": "a68e85ccf296d81a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:19.516318Z",
     "start_time": "2025-07-02T16:19:19.039520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Heatmap: average annual CF by country\n",
    "def make_heatmap(cf_lcoe_stats, tech, filename=None):\n",
    "\n",
    "    cf_lcoe_stats_pivot = cf_lcoe_stats[tech].set_index('CtryName')[['avg_CF']]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(cf_lcoe_stats_pivot, annot=True, cmap='YlOrRd', cbar_kws={'label': 'Average Annual CF'})\n",
    "    plt.title('Average Annual Capacity Factor by Country')\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    make_heatmap(cf_lcoe_stats, tech, filename=os.path.join('output', f'heatmap_{tech}_annual_cf.png'))"
   ],
   "id": "aed90c3b51004c78",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:20:00.351776Z",
     "start_time": "2025-07-02T16:19:59.618509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to approximate monthly CF from 8760-hour profile\n",
    "def approximate_monthly_cf(hourly_row):\n",
    "    hours_per_month = [744, 672, 744, 720, 744, 720, 744, 744, 720, 744, 720, 744]  # hours/month\n",
    "    monthly_cf = []\n",
    "    cursor = 0\n",
    "    for h in hours_per_month:\n",
    "        monthly_cf.append(hourly_row[cursor:cursor+h].mean())\n",
    "        cursor += h\n",
    "    return monthly_cf\n",
    "\n",
    "def make_monthly_heatmap(hourly_profiles, tech, filename=None):\n",
    "    monthly_cf_dict = {}\n",
    "    for _, row in hourly_profiles[tech].iterrows():\n",
    "        country = row['CtryName']\n",
    "        hourly_values = row.drop('CtryName').astype(float).values\n",
    "        monthly_cf_dict[country] = approximate_monthly_cf(hourly_values)\n",
    "\n",
    "    monthly_cf_df = pd.DataFrame.from_dict(monthly_cf_dict, orient='index',\n",
    "                                           columns=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.heatmap(monthly_cf_df, cmap='YlGnBu', linewidths=0.5, cbar_kws={'label': 'Monthly CF'})\n",
    "    plt.title('Monthly Average Capacity Factor by Country')\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    make_monthly_heatmap(hourly_profiles, tech, filename=os.path.join('output', f'heatmap_{tech}_monthly_cf.png'))"
   ],
   "id": "56cba9a76d5ace2",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22d094a0dce5c893"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
