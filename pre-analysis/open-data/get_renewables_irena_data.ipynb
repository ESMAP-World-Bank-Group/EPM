{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Wind and Solar Data from IRENA\n",
    "\n",
    "**Objective**\n",
    "Summarize IRENA Model Supply Regions (MSR) outputs\u2014capacity factors, LCOE, and hourly profiles\u2014for the countries plugged into the SPLAT supply model.\n",
    "\n",
    "**Data Requirements & Methods**\n",
    "- Place `SolarPV_BestMSRsToCover5%CountryArea.csv` and `Wind_BestMSRsToCover5%CountryArea.csv` into `pre-analysis/open-data/input/`.\n",
    "- Provide the country list in SPLAT naming conventions and ensure dependencies (`pandas`, `matplotlib`, `geopy`, `timezonefinder`, etc.) are installed.\n",
    "- The notebook validates inputs, computes weighted statistics by technology, aligns time zones, and prepares visualization-ready tables.\n",
    "\n",
    "**Overview of Steps**\n",
    "1. Step 1 - Import libraries and declare study countries.\n",
    "2. Step 2 - Confirm the required MSR CSV inputs exist.\n",
    "3. Step 3 - Process MSR data to compute weighted LCOE/CF stats and hourly profiles.\n",
    "4. Step 4 - Visualize country-level diagnostics (heatmaps and monthly profiles).\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:47.555414Z",
     "start_time": "2025-07-02T16:17:47.395040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timezonefinder import TimezoneFinder\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import pytz"
   ],
   "id": "2ee90bed91285872",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1 - Configure user settings\n",
    "List the SPLAT country names you want to analyze and confirm the count before loading data.\n",
    "\n"
   ],
   "id": "413ed4e31a3f6216"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:48.574577Z",
     "start_time": "2025-07-02T16:17:48.571663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "countries = ['Angola', 'Burundi', 'DemocraticRepublicoftheCongo', 'Cameroon', 'Rwanda', 'CentralAfricanRepublic', 'Chad', 'Congo', 'Gabon', 'EquatorialGuinea', 'SaoTomeandPrincipe']\n",
    "\n",
    "print(f'Number of countries: {len(countries)}')"
   ],
   "id": "cddd7864b068403d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries: 11\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2 - Load MSR inputs\n",
    "Verify that the Solar PV and Wind MSR CSV files exist in the `input/` directory before continuing.\n",
    "\n"
   ],
   "id": "4a6f8127a4f6b65e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:50.192024Z",
     "start_time": "2025-07-02T16:17:50.188736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_solarMSR = os.path.join('input', 'SolarPV_BestMSRsToCover5%CountryArea.csv')\n",
    "if not os.path.exists(file_solarMSR):\n",
    "    raise FileNotFoundError(f\"The file {file_solarMSR} does not exist. Please download the Solar PV MSR data and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_solarMSR} found. Proceeding with the analysis.\")"
   ],
   "id": "2b9ddb23aa036c08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/SolarPV_BestMSRsToCover5%CountryArea.csv found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:50.775050Z",
     "start_time": "2025-07-02T16:17:50.771160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_windMSR = os.path.join('input', 'Wind_BestMSRsToCover5%CountryArea.csv')\n",
    "if not os.path.exists(file_windMSR):\n",
    "    raise FileNotFoundError(f\"The file {file_windMSR} does not exist. Please download the Solar PV MSR data and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_windMSR} found. Proceeding with the analysis.\")"
   ],
   "id": "aa428ef5a984e8a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/Wind_BestMSRsToCover5%CountryArea.csv found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3 - Process MSR data\n",
    "Derive time zones, compute weighted capacity-factor and LCOE statistics, and reshape hourly profiles for each technology.\n",
    "\n"
   ],
   "id": "34798dbbab0b3f11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:18:58.202617Z",
     "start_time": "2025-07-02T16:18:45.526536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocess step to get country time zone. This step is necessary as IRENA data is expressed in local time. To account for a common time reference, those times need to be transformed into UTC time. To do so, each country time zone must be obtained\n",
    "\n",
    "# Warning: this step may take a few dozen seconds\n",
    "\n",
    "def extract_time_zone(countries, name_map):\n",
    "    \"\"\"\n",
    "    Extracts the time zone (IANA tz database name, e.g., 'Africa/Luanda') for each country in a given list.\n",
    "\n",
    "    This function takes a list of country names used in SPLAT (which may use non-standard naming conventions)\n",
    "    and a mapping (`name_map`) from SPLAT-style names to standard country names (as recognized by geocoding services).\n",
    "    It uses the `geopy` package to geocode each standard country name and `timezonefinder` to identify the time zone\n",
    "    at the country centroid.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    countries : list of str\n",
    "        List of SPLAT-style country names (e.g., ['SouthAfrica', 'DemocraticRepublicoftheCongo']).\n",
    "\n",
    "    name_map : dict\n",
    "        Dictionary mapping SPLAT-style names to standard country names\n",
    "        (e.g., {'SouthAfrica': 'South Africa'}).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping original SPLAT-style names to their IANA timezone name\n",
    "        (e.g., {'SouthAfrica': 'Africa/Johannesburg'}).\n",
    "    \"\"\"\n",
    "    standard_names = [name_map.get(c, c) for c in countries]\n",
    "\n",
    "    # Initialize timezone and geolocation tools\n",
    "    tf = TimezoneFinder()\n",
    "    geolocator = Nominatim(user_agent=\"splat_timezones\")\n",
    "\n",
    "    # Build timezone dictionary\n",
    "    country_timezones = {}\n",
    "\n",
    "    for name, std_name in zip(countries, standard_names):\n",
    "        try:\n",
    "            location = geolocator.geocode(std_name, timeout=10)\n",
    "            if location:\n",
    "                tz = tf.timezone_at(lat=location.latitude, lng=location.longitude)\n",
    "                country_timezones[name] = tz\n",
    "            else:\n",
    "                print(f\"Could not geocode: {std_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {std_name}: {e}\")\n",
    "\n",
    "        time.sleep(1)  # avoid overloading the API\n",
    "    return country_timezones\n",
    "\n",
    "# Manual correction to standard names (to help geocoder or pycountry). Transform names used in the IRENA / SPLAT database into official country names.\n",
    "# You only need to specify countries for which the SPLAT name does not correspond to official country name\n",
    "name_map = {\n",
    "    'SouthAfrica': 'South Africa',\n",
    "    'DemocraticRepublicoftheCongo': 'Democratic Republic of the Congo',\n",
    "    'UnitedRepublicofTanzania': 'Tanzania',\n",
    "    'CentralAfricanRepublic': 'Central African Republic',\n",
    "    'SaoTomeandPrincipe': 'Sao Tome and Principe'\n",
    "    # The others are fine\n",
    "}\n",
    "\n",
    "country_timezones = extract_time_zone(countries, name_map)"
   ],
   "id": "c2021b1c20682e26",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:01.028619Z",
     "start_time": "2025-07-02T16:19:01.019596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We define capex parameters used in their model\n",
    "# They use a discount rate of 10%, and lifetime of 25 years for generation, 40 years for transmission\n",
    "CAPEX_PARAMETERS = {\n",
    "    'solar': {\n",
    "        'supply_asset_capital_recovery': 0.1101681,\n",
    "        'operating_costs': 4,\n",
    "        'fixed_costs': 53500\n",
    "    },\n",
    "    'wind': {\n",
    "        'supply_asset_capital_recovery': 0.1101681,\n",
    "        'operating_costs': 0,\n",
    "        'fixed_costs': 64200\n",
    "    },\n",
    "    'grid': {\n",
    "        'supply_asset_capital_recovery': 0.102259,\n",
    "    },\n",
    "    'road': {\n",
    "        'supply_asset_capital_recovery': 0.11017,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def compute_weighted_stats(group, tech):\n",
    "    \"\"\"Weighted statistics across all relevant clusters for a given country. We use the theoretical available capacity in a given cluster as the weight.\"\"\"\n",
    "    avg_cf = (group[column_cf] * group['CapacityMW']).sum() / group['CapacityMW'].sum()  # MWh / MW\n",
    "    avg_lcoe = (group['LCOE-MWh'] * group['CapacityMW']).sum() / group['CapacityMW'].sum()  # $ / MWh\n",
    "    # For the LCOE, we use the breakdown of the LCOE into different components (generation, road and transmission), and the capital recovery rates used in the MSR model\n",
    "    cost_per_MW = ((((group['sLCOE-MWh'] - CAPEX_PARAMETERS[tech]['operating_costs'])  * (8760 * group[column_cf] / 100) - CAPEX_PARAMETERS[tech]['fixed_costs']) / CAPEX_PARAMETERS[tech]['supply_asset_capital_recovery'] + (group['tLCOE-MWh']  * (8760 * group[column_cf] / 100)) / CAPEX_PARAMETERS['grid']['supply_asset_capital_recovery'] + (group['rLCOE-MWh']  * (8760 * group[column_cf] / 100)) / CAPEX_PARAMETERS['road']['supply_asset_capital_recovery'])  * group['CapacityMW']).sum() / group['CapacityMW'].sum()  * 1e-6  # costs in m$ / MW\n",
    "    \n",
    "    return pd.Series({\n",
    "        'avg_CF': avg_cf,\n",
    "        'avg_LCOE': avg_lcoe,\n",
    "        'cost_per_MW': cost_per_MW\n",
    "    })\n",
    "\n",
    "\n",
    "# Weighted hourly profile for each country\n",
    "def weighted_hourly_profile(group):\n",
    "    weights = group['CapacityMW'].values.reshape(-1, 1)\n",
    "    hourly_data = group[hourly_cols].values\n",
    "    weighted_avg = (hourly_data * weights).sum(axis=0) / weights.sum()\n",
    "    return pd.Series(weighted_avg, index=hourly_cols)\n",
    "\n",
    "def convert_to_utc(row, country_timezones):\n",
    "    \"\"\"\n",
    "    Converts a local timestamp to UTC based on the country's time zone.\n",
    "\n",
    "    This function is designed to be used within a pandas `.apply()` call\n",
    "    to convert a 'timestamp' column (assumed local time) into UTC, using\n",
    "    a dictionary that maps each country name to its IANA time zone string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pd.Series\n",
    "        A row from the DataFrame containing at least 'CtryName' and 'timestamp'.\n",
    "    country_timezones : dict\n",
    "        Dictionary mapping country names (as in 'CtryName') to their IANA time zone names,\n",
    "        e.g., {'SouthAfrica': 'Africa/Johannesburg'}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datetime\n",
    "        The timestamp converted to UTC timezone.\n",
    "    \"\"\"\n",
    "    ctry = row['CtryName']\n",
    "    local_zone = pytz.timezone(country_timezones[ctry])\n",
    "    local_time = local_zone.localize(row['timestamp'], is_dst=None)\n",
    "    return local_time.astimezone(pytz.utc)\n"
   ],
   "id": "10acb50231f6a135",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:19.016678Z",
     "start_time": "2025-07-02T16:19:01.645416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cf_lcoe_stats = {}\n",
    "hourly_profiles = {}\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    if tech == 'wind':\n",
    "        file = file_windMSR\n",
    "        column_cf = 'CF100m'\n",
    "    else:\n",
    "        file = file_solarMSR\n",
    "        column_cf = 'CF'\n",
    "\n",
    "    # Select relevant columns\n",
    "    meta_cols = ['CtryName', 'CapacityMW', column_cf, 'sLCOE-MWh', 'tLCOE-MWh', 'rLCOE-MWh', 'LCOE-MWh']\n",
    "    hourly_cols = [f'H{i}' for i in range(1, 8761)]  # if needed\n",
    "\n",
    "    # Combine what you need\n",
    "    use_columns = meta_cols + hourly_cols  # or just meta_cols to start\n",
    "\n",
    "    data_MSR_stats = pd.read_csv(file, usecols=use_columns, header=0)\n",
    "    data_MSR_stats = data_MSR_stats[data_MSR_stats['CtryName'].isin([c for c in countries])]\n",
    "\n",
    "    cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
    "\n",
    "    data_MSR_hourlyprofile = data_MSR_stats.set_index(['CtryName', 'CapacityMW'])[hourly_cols].reset_index()\n",
    "    hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
    "\n",
    "    # Saving data in good format for representative days analysis\n",
    "    date_index = pd.date_range(start='2023-01-01', periods=8760, freq='h')  # 2023 is a non-leap year\n",
    "\n",
    "    df_long = hourly_profiles[tech].melt(id_vars='CtryName', var_name='Hour', value_name='value')\n",
    "\n",
    "    # Convert 'H1', ..., 'H8760' to integer hour index\n",
    "    df_long['hour_index'] = df_long['Hour'].str.extract('H(\\d+)').astype(int) - 1  # zero-based index\n",
    "\n",
    "    df_long['timestamp'] = df_long['hour_index'].map(lambda i: date_index[i])\n",
    "\n",
    "    # Convert local time to UTC\n",
    "    df_long['CtryName'] = df_long['CtryName'].astype(str)  # just in case\n",
    "    df_long['timestamp_utc'] = df_long.apply(lambda row: convert_to_utc(row, country_timezones), axis=1)\n",
    "\n",
    "    # Create season, day and hours\n",
    "    df_long['season'] = df_long['timestamp_utc'].dt.month\n",
    "    df_long['day'] = df_long['timestamp_utc'].dt.day\n",
    "    df_long['hour'] = df_long['timestamp_utc'].dt.hour\n",
    "\n",
    "    # Step 5: Rename and index\n",
    "    df_long = df_long.rename(columns={'CtryName': 'zone'})\n",
    "    df_final = df_long.set_index(['zone', 'season', 'day', 'hour'])['value']\n",
    "    df_final = df_final.to_frame().rename(columns={'value': 2018}).sort_values(by=['season', 'day', 'hour'])\n",
    "\n",
    "    df_final.to_csv(os.path.join('output', f'data_SAPP_{tech}.csv'), index=True)"
   ],
   "id": "b26efb45d80c4e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:28: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_index = pd.date_range(start='2023-01-01', periods=8760, freq='H')  # 2023 is a non-leap year\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_34305/4263247223.py:28: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_index = pd.date_range(start='2023-01-01', periods=8760, freq='H')  # 2023 is a non-leap year\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4 - Visualize the results\n",
    "Create heatmaps and monthly profile summaries so stakeholders can quickly compare wind and solar performance across countries.\n",
    "\n"
   ],
   "id": "dd073cd811ad0107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Make heatmap",
   "id": "a68e85ccf296d81a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:19.516318Z",
     "start_time": "2025-07-02T16:19:19.039520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Heatmap: average annual CF by country\n",
    "def make_heatmap(cf_lcoe_stats, tech, filename=None):\n",
    "\n",
    "    cf_lcoe_stats_pivot = cf_lcoe_stats[tech].set_index('CtryName')[['avg_CF']]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(cf_lcoe_stats_pivot, annot=True, cmap='YlOrRd', cbar_kws={'label': 'Average Annual CF'})\n",
    "    plt.title('Average Annual Capacity Factor by Country')\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    make_heatmap(cf_lcoe_stats, tech, filename=os.path.join('output', f'heatmap_{tech}_annual_cf.png'))"
   ],
   "id": "aed90c3b51004c78",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:20:00.351776Z",
     "start_time": "2025-07-02T16:19:59.618509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to approximate monthly CF from 8760-hour profile\n",
    "def approximate_monthly_cf(hourly_row):\n",
    "    hours_per_month = [744, 672, 744, 720, 744, 720, 744, 744, 720, 744, 720, 744]  # hours/month\n",
    "    monthly_cf = []\n",
    "    cursor = 0\n",
    "    for h in hours_per_month:\n",
    "        monthly_cf.append(hourly_row[cursor:cursor+h].mean())\n",
    "        cursor += h\n",
    "    return monthly_cf\n",
    "\n",
    "def make_monthly_heatmap(hourly_profiles, tech, filename=None):\n",
    "    monthly_cf_dict = {}\n",
    "    for _, row in hourly_profiles[tech].iterrows():\n",
    "        country = row['CtryName']\n",
    "        hourly_values = row.drop('CtryName').astype(float).values\n",
    "        monthly_cf_dict[country] = approximate_monthly_cf(hourly_values)\n",
    "\n",
    "    monthly_cf_df = pd.DataFrame.from_dict(monthly_cf_dict, orient='index',\n",
    "                                           columns=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                                                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.heatmap(monthly_cf_df, cmap='YlGnBu', linewidths=0.5, cbar_kws={'label': 'Monthly CF'})\n",
    "    plt.title('Monthly Average Capacity Factor by Country')\n",
    "    plt.tight_layout()\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    make_monthly_heatmap(hourly_profiles, tech, filename=os.path.join('output', f'heatmap_{tech}_monthly_cf.png'))"
   ],
   "id": "56cba9a76d5ace2",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22d094a0dce5c893"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}