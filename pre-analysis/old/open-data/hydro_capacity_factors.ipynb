{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydropower Capacity Factors\n",
    "\n",
    "**Objective**\n",
    "Blend cleaned EPM generation inputs with the African Hydropower Atlas to derive seasonal availability (`pAvailability`) for reservoirs and `pVREgenProfile` templates for run-of-river assets.\n",
    "\n",
    "**Data Requirements & Methods**\n",
    "- `pGenDataInput_clean.csv` plus `pHours.csv` available under `epm/input/data_capp/`.\n",
    "- `African_Hydropower_Atlas_v2-0.xlsx` stored inside `pre-analysis/open-data/input/`.\n",
    "- The notebook filters hydropower units, merges them with Hydrofleet scenarios, aggregates to user-defined seasons, and writes the CSVs that feed EPM.\n",
    "\n",
    "**Overview of Steps**\n",
    "1. Step 1 - Load and filter EPM generation data for hydropower technologies.\n",
    "2. Step 2 - Load Hydrofleet scenarios from the African Hydropower Atlas.\n",
    "3. Step 3 - Merge the datasets and define seasonal groupings.\n",
    "4. Step 4 - Export reservoir `pAvailability` tables by scenario.\n",
    "5. Step 5 - Build run-of-river `pVREgenProfile` templates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f37f95a697cb6f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T08:55:06.988954Z",
     "start_time": "2025-07-01T08:55:06.288813Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16e7930d23d40a",
   "metadata": {},
   "source": [
    "## Step 1 - Load EPM generation data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a84639257304ea77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:11:34.699783Z",
     "start_time": "2025-07-01T09:11:34.687382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../../epm/input/data_capp/supply/pGenDataInput_clean.csv found. Proceeding with the analysis.\n",
      "                                   zone            tech   fuel  Status  StYr  \\\n",
      "gen                                                                            \n",
      "Lauca                            Angola  ReservoirHydro  Water       1  2017   \n",
      "Cambambe 2                       Angola  ReservoirHydro  Water       1  2016   \n",
      "Capanda                          Angola  ReservoirHydro  Water       1  2004   \n",
      "Cambambe 1                       Angola  ReservoirHydro  Water       1  1962   \n",
      "1smallhydrodro2012_hydro_angola  Angola  ReservoirHydro  Water       1  2012   \n",
      "\n",
      "                                 RetrYr  Capacity  DescreteCap  fuel2  \\\n",
      "gen                                                                     \n",
      "Lauca                              2050    2070.0          NaN    NaN   \n",
      "Cambambe 2                         2050     700.0          NaN    NaN   \n",
      "Capanda                            2050     520.0          NaN    NaN   \n",
      "Cambambe 1                         2050     260.0          NaN    NaN   \n",
      "1smallhydrodro2012_hydro_angola    2050     136.0          NaN    NaN   \n",
      "\n",
      "                                 HeatRate2  ...  MinLimitShare  HeatRate  \\\n",
      "gen                                         ...                            \n",
      "Lauca                                  NaN  ...            NaN       NaN   \n",
      "Cambambe 2                             NaN  ...            NaN       NaN   \n",
      "Capanda                                NaN  ...            NaN       NaN   \n",
      "Cambambe 1                             NaN  ...            NaN       NaN   \n",
      "1smallhydrodro2012_hydro_angola        NaN  ...            NaN       NaN   \n",
      "\n",
      "                                 RampUpRate  RampDnRate  OverLoadFactor  \\\n",
      "gen                                                                       \n",
      "Lauca                                   NaN         NaN             NaN   \n",
      "Cambambe 2                              NaN         NaN             NaN   \n",
      "Capanda                                 NaN         NaN             NaN   \n",
      "Cambambe 1                              NaN         NaN             NaN   \n",
      "1smallhydrodro2012_hydro_angola         NaN         NaN             NaN   \n",
      "\n",
      "                                 ResLimShare  Capex  FOMperMW  VOM  \\\n",
      "gen                                                                  \n",
      "Lauca                                    NaN    NaN       NaN  NaN   \n",
      "Cambambe 2                               NaN    NaN       NaN  NaN   \n",
      "Capanda                                  NaN    NaN       NaN  NaN   \n",
      "Cambambe 1                               NaN    NaN       NaN  NaN   \n",
      "1smallhydrodro2012_hydro_angola          NaN    NaN       NaN  NaN   \n",
      "\n",
      "                                 ReserveCost  \n",
      "gen                                           \n",
      "Lauca                                    NaN  \n",
      "Cambambe 2                               NaN  \n",
      "Capanda                                  NaN  \n",
      "Cambambe 1                               NaN  \n",
      "1smallhydrodro2012_hydro_angola          NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = 'pGenDataInput_clean.csv'\n",
    "folder_epm = os.path.join('..', '..', 'epm', 'input', 'data_capp')\n",
    "file_path = os.path.join(folder_epm, 'supply', filename)\n",
    "if not os.path.exists(file_path):\n",
    "    # Display the total path to the file, not relative\n",
    "    raise FileNotFoundError(f\"The file {os.path.abspath(file_path)} does not exist. Please check the path.\")\n",
    "else:\n",
    "    print(f\"File {file_path} found. Proceeding with the analysis.\")\n",
    "\n",
    "# Load the generation data\n",
    "data_gen = pd.read_csv(file_path, index_col=None, header=[0])\n",
    "\n",
    "# Filter hydropower plants\n",
    "data_gen = data_gen[data_gen['tech'].isin(['ROR', 'ReservoirHydro'])]\n",
    "\n",
    "data_gen.set_index(['gen'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the generation data\n",
    "print(data_gen.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63dd4e5335591da",
   "metadata": {},
   "source": [
    "## Step 2 - Load the African Hydropower Atlas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5003fd0454c8d2f",
   "metadata": {},
   "source": [
    "Download the African Hydropower Atlas from the [African Hydropower Atlas](https://www.hydroshare.org/resource/5e8ebdc3bfd24207852539ecf219d915/) website, and put it in the `input` folder.\n",
    "\n",
    "The file should be named `African_Hydropower_Atlas_v2-0.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cc03370613b4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T08:55:07.145198Z",
     "start_time": "2025-07-01T08:55:07.141402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/African_Hydropower_Atlas_v2-0.xlsx found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "source": [
    "file_atlas = os.path.join('input', 'African_Hydropower_Atlas_v2-0.xlsx')\n",
    "if not os.path.exists(file_atlas):\n",
    "    raise FileNotFoundError(f\"The file {file_atlas} does not exist. Please download the African Hydropower Atlas and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_atlas} found. Proceeding with the analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2671505bfa1677eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T08:55:30.091124Z",
     "start_time": "2025-07-01T08:55:30.002377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario        baseline                                                    \\\n",
      "month                 1    2    3    4    5         6         7         8    \n",
      "Unit Name                                                                    \n",
      "Ighil Emda      0.857215  1.0  1.0  1.0  1.0  0.388244  0.035388  0.003170   \n",
      "Erraguene       1.000000  1.0  1.0  1.0  1.0  0.446470  0.041604  0.023276   \n",
      "Mansouria       1.000000  1.0  1.0  1.0  1.0  0.446470  0.041604  0.023276   \n",
      "Darguina        0.857215  1.0  1.0  1.0  1.0  0.388244  0.035388  0.003170   \n",
      "Souk El Djemaa       NaN  NaN  NaN  NaN  NaN       NaN       NaN       NaN   \n",
      "\n",
      "scenario                            ...  wet                                \\\n",
      "month                 9         10  ...   3    4    5         6         7    \n",
      "Unit Name                           ...                                      \n",
      "Ighil Emda      0.203179  0.185520  ...  1.0  1.0  1.0  0.669888  0.061060   \n",
      "Erraguene       0.075531  0.092803  ...  1.0  1.0  1.0  1.000000  0.098062   \n",
      "Mansouria       0.075531  0.092803  ...  1.0  1.0  1.0  1.000000  0.098062   \n",
      "Darguina        0.203179  0.185520  ...  1.0  1.0  1.0  0.669888  0.061060   \n",
      "Souk El Djemaa       NaN       NaN  ...  NaN  NaN  NaN       NaN       NaN   \n",
      "\n",
      "scenario                                                     \n",
      "month                 8         9         10        11   12  \n",
      "Unit Name                                                    \n",
      "Ighil Emda      0.005469  0.350570  0.320101  1.000000  1.0  \n",
      "Erraguene       0.054863  0.178029  0.218740  0.686915  1.0  \n",
      "Mansouria       0.054863  0.178029  0.218740  0.686915  1.0  \n",
      "Darguina        0.005469  0.350570  0.320101  1.000000  1.0  \n",
      "Souk El Djemaa       NaN       NaN       NaN       NaN  NaN  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "data_atlas = pd.read_excel(file_atlas, sheet_name='2 - Hydrofleet2020', index_col=None, skiprows=None, header=0)\n",
    "data_atlas.rename(columns={'Name': 'Unit Name'}, inplace=True)\n",
    "data_atlas.set_index(['Country', 'Unit Name'], inplace=True)\n",
    "\n",
    "data_atlas = data_atlas.droplevel('Country')\n",
    "# Rename columns to match the expected format\n",
    "cols = pd.MultiIndex.from_product([['baseline', 'dry', 'wet'], range(1, 13)], names=['scenario', 'month'])\n",
    "# Add scenarios to the columns\n",
    "data_atlas = data_atlas.set_axis(cols, axis=1)\n",
    "\n",
    "print(data_atlas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2855a4879bd99f",
   "metadata": {},
   "source": [
    "## Step 3 - Merge generation data with Hydrofleet scenarios\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9766053287f553a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:07:27.924537Z",
     "start_time": "2025-07-01T09:07:27.919520Z"
    }
   },
   "outputs": [],
   "source": [
    "seasons_dict = {\n",
    "    1: 2,\n",
    "    2: 2,\n",
    "    3: 2,\n",
    "    4: 2,\n",
    "    5: 1,\n",
    "    6: 1,\n",
    "    7: 1,\n",
    "    8: 1,\n",
    "    9: 1,\n",
    "    10: 2,\n",
    "    11: 2,\n",
    "    12: 2\n",
    "}  # grouping months into 4 seasons, to define according to user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b4dceab7be0a34d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:02:23.848166Z",
     "start_time": "2025-07-01T09:02:23.836874Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ror = data_gen[data_gen['tech'] == 'ROR'].copy()\n",
    "data_reservoir = data_gen[data_gen['tech'] == 'ReservoirHydro'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8603ad7559928",
   "metadata": {},
   "source": [
    "## Step 4 - Generate pAvailability for reservoirs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "365dc4995986425f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:10:22.523074Z",
     "start_time": "2025-07-01T09:10:22.507902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pAvailability_baseline.csv with shape (67, 2).\n",
      "Saved pAvailability_dry.csv with shape (67, 2).\n",
      "Saved pAvailability_wet.csv with shape (67, 2).\n"
     ]
    }
   ],
   "source": [
    "for s in data_atlas.columns.get_level_values('scenario').unique():\n",
    "    # Filter the data for the current scenario\n",
    "    data_atlas_scenario = data_atlas.xs(s, level='scenario', axis=1)\n",
    "\n",
    "    # Keep only the index from data_gen\n",
    "    result = data_reservoir.join(data_atlas_scenario, how=\"left\")\n",
    "\n",
    "    # Keep only columns from data_atlas\n",
    "    result = result[data_atlas_scenario.columns]\n",
    "\n",
    "    # Group by the seasons defined in seasons_dict\n",
    "    result = result.T.groupby(seasons_dict).mean().T\n",
    "\n",
    "    # Add 'Q{}' prefix to the column names\n",
    "    result.columns = [f'Q{col}' for col in result.columns]\n",
    "\n",
    "    filename = f'pAvailability_{s}.csv'\n",
    "    result.to_csv(os.path.join('output', filename))\n",
    "    print(f\"Saved {filename} with shape {result.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b81902d1afe1d9",
   "metadata": {},
   "source": [
    "## Step 5 - Generate pVREgenProfile for run-of-river plants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f1f89ba115bf999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:28:59.494199Z",
     "start_time": "2025-07-01T09:28:59.487522Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_pVREgenProfile(result, template):\n",
    "    \"\"\"Generate pVREgenProfile for ROR plants.\n",
    "\n",
    "    This function takes a scenario identifier and a template DataFrame,\n",
    "    and generates a pVREgenProfile DataFrame for Run-of-River (ROR) plants.\n",
    "    It reshapes the result DataFrame to match the template structure,\n",
    "    broadcasting the values across all hour columns.\n",
    "\n",
    "    Parameters:\n",
    "        s: str\n",
    "            The scenario identifier, used for naming the output file.\n",
    "        template: pd.DataFrame\n",
    "            The template DataFrame that defines the structure of the output.\n",
    "    \"\"\"\n",
    "\n",
    "    result_reset = result.reset_index()  # so 'gen' becomes a column\n",
    "    result_long = result_reset.melt(id_vars='gen', var_name='season', value_name='value')\n",
    "\n",
    "    daytypes = template.reset_index()[['season', 'daytype']].drop_duplicates()\n",
    "    merged = result_long.merge(daytypes, on='season', how='left')\n",
    "\n",
    "    # get hour columns from template\n",
    "    hour_cols = template.columns.difference(['season', 'daytype'])\n",
    "\n",
    "    # broadcast the value across all hour columns\n",
    "    for col in hour_cols:\n",
    "        merged[col] = merged['value']\n",
    "\n",
    "    merged_final = merged.drop(columns=['value'])\n",
    "    merged_final = merged_final.set_index(['gen', 'season', 'daytype'])\n",
    "    merged_final.index.names = ['gen', 'q', 'd']\n",
    "\n",
    "    return merged_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf2fc14548e04859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:29:01.375964Z",
     "start_time": "2025-07-01T09:29:01.370041Z"
    }
   },
   "outputs": [],
   "source": [
    "template = pd.read_csv(os.path.join(folder_epm, 'pHours.csv'), index_col=[0, 1], header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adacfeba9e2cb397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:29:14.333461Z",
     "start_time": "2025-07-01T09:29:14.280702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pVREgenProfile_baseline.csv with shape (670, 24).\n",
      "Saved pVREgenProfile_dry.csv with shape (670, 24).\n",
      "Saved pVREgenProfile_wet.csv with shape (670, 24).\n"
     ]
    }
   ],
   "source": [
    "for s in data_atlas.columns.get_level_values('scenario').unique():\n",
    "    # Filter the data for the current scenario\n",
    "    data_atlas_scenario = data_atlas.xs(s, level='scenario', axis=1)\n",
    "\n",
    "    # Keep only the index from data_gen\n",
    "    result = data_reservoir.join(data_atlas_scenario, how=\"left\")\n",
    "\n",
    "    # Keep only columns from data_atlas\n",
    "    result = result[data_atlas_scenario.columns]\n",
    "\n",
    "    # Group by the seasons defined in seasons_dict\n",
    "    result = result.T.groupby(seasons_dict).mean().T\n",
    "\n",
    "    # Add 'Q{}' prefix to the column names\n",
    "    result.columns = [f'Q{col}' for col in result.columns]\n",
    "    result.columns.names = ['season']\n",
    "\n",
    "    result = generate_pVREgenProfile(result, template)\n",
    "\n",
    "    result.to_csv(os.path.join('output', f'pVREgenProfile_{s}.csv'))\n",
    "    print(f'Saved pVREgenProfile_{s}.csv with shape {result.shape}.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esmap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}