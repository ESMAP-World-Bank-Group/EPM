{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Wind and Solar Data from IRENA\n",
    "\n",
    "**Objective**\n",
    "Summarize IRENA Model Supply Regions (MSR) outputs—capacity factors, LCOE, and hourly profiles—for the countries plugged into the SPLAT supply model.\n",
    "\n",
    "**Data Requirements & Methods**\n",
    "- Place `SolarPV_BestMSRsToCover5%CountryArea.csv` and `Wind_BestMSRsToCover5%CountryArea.csv` into `pre-analysis/open-data/input/`.\n",
    "- Provide the country list in SPLAT naming conventions and ensure dependencies (`pandas`, `matplotlib`, `geopy`, `timezonefinder`, etc.) are installed.\n",
    "- The notebook validates inputs, computes weighted statistics by technology, aligns time zones, and prepares visualization-ready tables.\n",
    "\n",
    "**Overview of Steps**\n",
    "1. Step 1 - Import libraries and declare study countries.\n",
    "2. Step 2 - Confirm the required MSR CSV inputs exist.\n",
    "3. Step 3 - Process MSR data to compute weighted LCOE/CF stats and hourly profiles.\n",
    "4. Step 4 - Visualize country-level diagnostics (heatmaps and monthly profiles).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee90bed91285872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:47.555414Z",
     "start_time": "2025-07-02T16:17:47.395040Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "\n",
    "from utils_renewables import extract_time_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ed4e31a3f6216",
   "metadata": {},
   "source": [
    "## Step 1 - Configure user settings\n",
    "List the SPLAT country names you want to analyze and confirm the count before loading data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddd7864b068403d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:48.574577Z",
     "start_time": "2025-07-02T16:17:48.571663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries: 6\n"
     ]
    }
   ],
   "source": [
    "countries = [\n",
    "    'Bosnia and Herzegovina',\n",
    "    'Croatia',\n",
    "    'Serbia',\n",
    "    'Montenegro',\n",
    "    'North Macedonia',\n",
    "    'Albania'\n",
    "]\n",
    "print(f'Number of countries: {len(countries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f8127a4f6b65e",
   "metadata": {},
   "source": [
    "## Step 2 - Load MSR inputs\n",
    "Verify that the Solar PV and Wind MSR CSV files exist in the `input/` directory before continuing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9ddb23aa036c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:50.192024Z",
     "start_time": "2025-07-02T16:17:50.188736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/SolarPV_BestMSRsToCover5%CountryArea.csv found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "source": [
    "file_solarMSR = os.path.join('input', 'SolarPV_BestMSRsToCover5%CountryArea.csv')\n",
    "if not os.path.exists(file_solarMSR):\n",
    "    raise FileNotFoundError(f\"The file {file_solarMSR} does not exist. Please download the Solar PV MSR data and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_solarMSR} found. Proceeding with the analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa428ef5a984e8a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:17:50.775050Z",
     "start_time": "2025-07-02T16:17:50.771160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File input/Wind_BestMSRsToCover5%CountryArea.csv found. Proceeding with the analysis.\n"
     ]
    }
   ],
   "source": [
    "file_windMSR = os.path.join('input', 'Wind_BestMSRsToCover5%CountryArea.csv')\n",
    "if not os.path.exists(file_windMSR):\n",
    "    raise FileNotFoundError(f\"The file {file_windMSR} does not exist. Please download the Solar PV MSR data and place it in the input folder.\")\n",
    "else:\n",
    "    print(f\"File {file_windMSR} found. Proceeding with the analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34798dbbab0b3f11",
   "metadata": {},
   "source": [
    "## Step 3 - Process MSR data\n",
    "Derive time zones, compute weighted capacity-factor and LCOE statistics, and reshape hourly profiles for each technology.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2021b1c20682e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:18:58.202617Z",
     "start_time": "2025-07-02T16:18:45.526536Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess step to get country time zone. This step is necessary as IRENA data is expressed in local time. To account for a common time reference, those times need to be transformed into UTC time. To do so, each country time zone must be obtained\n",
    "\n",
    "# Warning: this step may take a few dozen seconds\n",
    "# Manual correction to standard names (to help geocoder or pycountry). Transform names used in the IRENA / SPLAT database into official country names.\n",
    "# You only need to specify countries for which the SPLAT name does not correspond to official country name\n",
    "name_map = {\n",
    "    'SouthAfrica': 'South Africa',\n",
    "    'DemocraticRepublicoftheCongo': 'Democratic Republic of the Congo',\n",
    "    'UnitedRepublicofTanzania': 'Tanzania',\n",
    "    'CentralAfricanRepublic': 'Central African Republic',\n",
    "    'SaoTomeandPrincipe': 'Sao Tome and Principe'\n",
    "    # The others are fine\n",
    "}\n",
    "\n",
    "country_timezones = extract_time_zone(countries, name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10acb50231f6a135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:01.028619Z",
     "start_time": "2025-07-02T16:19:01.019596Z"
    }
   },
   "outputs": [],
   "source": [
    "# We define capex parameters used in their model\n",
    "# They use a discount rate of 10%, and lifetime of 25 years for generation, 40 years for transmission\n",
    "CAPEX_PARAMETERS = {\n",
    "    'solar': {\n",
    "        'supply_asset_capital_recovery': 0.1101681,\n",
    "        'operating_costs': 4,\n",
    "        'fixed_costs': 53500\n",
    "    },\n",
    "    'wind': {\n",
    "        'supply_asset_capital_recovery': 0.1101681,\n",
    "        'operating_costs': 0,\n",
    "        'fixed_costs': 64200\n",
    "    },\n",
    "    'grid': {\n",
    "        'supply_asset_capital_recovery': 0.102259,\n",
    "    },\n",
    "    'road': {\n",
    "        'supply_asset_capital_recovery': 0.11017,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def compute_weighted_stats(group, tech):\n",
    "    \"\"\"Weighted statistics across all relevant clusters for a given country. We use the theoretical available capacity in a given cluster as the weight.\"\"\"\n",
    "    avg_cf = (group[column_cf] * group['CapacityMW']).sum() / group['CapacityMW'].sum()  # MWh / MW\n",
    "    avg_lcoe = (group['LCOE-MWh'] * group['CapacityMW']).sum() / group['CapacityMW'].sum()  # $ / MWh\n",
    "    # For the LCOE, we use the breakdown of the LCOE into different components (generation, road and transmission), and the capital recovery rates used in the MSR model\n",
    "    cost_per_MW = ((((group['sLCOE-MWh'] - CAPEX_PARAMETERS[tech]['operating_costs'])  * (8760 * group[column_cf] / 100) - CAPEX_PARAMETERS[tech]['fixed_costs']) / CAPEX_PARAMETERS[tech]['supply_asset_capital_recovery'] + (group['tLCOE-MWh']  * (8760 * group[column_cf] / 100)) / CAPEX_PARAMETERS['grid']['supply_asset_capital_recovery'] + (group['rLCOE-MWh']  * (8760 * group[column_cf] / 100)) / CAPEX_PARAMETERS['road']['supply_asset_capital_recovery'])  * group['CapacityMW']).sum() / group['CapacityMW'].sum()  * 1e-6  # costs in m$ / MW\n",
    "    \n",
    "    return pd.Series({\n",
    "        'avg_CF': avg_cf,\n",
    "        'avg_LCOE': avg_lcoe,\n",
    "        'cost_per_MW': cost_per_MW\n",
    "    })\n",
    "\n",
    "\n",
    "# Weighted hourly profile for each country\n",
    "def weighted_hourly_profile(group):\n",
    "    weights = group['CapacityMW'].values.reshape(-1, 1)\n",
    "    hourly_data = group[hourly_cols].values\n",
    "    weighted_avg = (hourly_data * weights).sum(axis=0) / weights.sum()\n",
    "    return pd.Series(weighted_avg, index=hourly_cols)\n",
    "\n",
    "def convert_to_utc(row, country_timezones):\n",
    "    \"\"\"\n",
    "    Converts a local timestamp to UTC based on the country's time zone.\n",
    "\n",
    "    This function is designed to be used within a pandas `.apply()` call\n",
    "    to convert a 'timestamp' column (assumed local time) into UTC, using\n",
    "    a dictionary that maps each country name to its IANA time zone string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pd.Series\n",
    "        A row from the DataFrame containing at least 'CtryName' and 'timestamp'.\n",
    "    country_timezones : dict\n",
    "        Dictionary mapping country names (as in 'CtryName') to their IANA time zone names,\n",
    "        e.g., {'SouthAfrica': 'Africa/Johannesburg'}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    datetime\n",
    "        The timestamp converted to UTC timezone.\n",
    "    \"\"\"\n",
    "    ctry = row['CtryName']\n",
    "    local_zone = pytz.timezone(country_timezones[ctry])\n",
    "    local_time = local_zone.localize(row['timestamp'], is_dst=None)\n",
    "    return local_time.astimezone(pytz.utc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26efb45d80c4e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:19.016678Z",
     "start_time": "2025-07-02T16:19:01.645416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_32498/3216447031.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert CtryName, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p9/3r4_fgzd72j7b469xxshgfnh0000gn/T/ipykernel_32498/3216447031.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Combine what you need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0muse_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhourly_cols\u001b[0m  \u001b[0;31m# or just meta_cols to start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdata_MSR_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdata_MSR_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_MSR_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_MSR_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CtryName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcf_lcoe_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtech\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_MSR_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CtryName'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_weighted_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtech\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/esmap_env/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6470\u001b[0m                     )\n\u001b[1;32m   6471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6472\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6473\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/esmap_env/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             )\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert CtryName, already exists"
     ]
    }
   ],
   "source": [
    "cf_lcoe_stats = {}\n",
    "hourly_profiles = {}\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    if tech == 'wind':\n",
    "        file = file_windMSR\n",
    "        column_cf = 'CF100m'\n",
    "    else:\n",
    "        file = file_solarMSR\n",
    "        column_cf = 'CF'\n",
    "\n",
    "    # Select relevant columns\n",
    "    meta_cols = ['CtryName', 'CapacityMW', column_cf, 'sLCOE-MWh', 'tLCOE-MWh', 'rLCOE-MWh', 'LCOE-MWh']\n",
    "    hourly_cols = [f'H{i}' for i in range(1, 8761)]  # if needed\n",
    "\n",
    "    # Combine what you need\n",
    "    use_columns = meta_cols + hourly_cols  # or just meta_cols to start\n",
    "\n",
    "    data_MSR_stats = pd.read_csv(file, usecols=use_columns, header=0)\n",
    "    data_MSR_stats = data_MSR_stats[data_MSR_stats['CtryName'].isin([c for c in countries])]\n",
    "\n",
    "    cf_lcoe_stats[tech] = data_MSR_stats.groupby('CtryName').apply(compute_weighted_stats, tech=tech).reset_index()\n",
    "\n",
    "    data_MSR_hourlyprofile = data_MSR_stats.set_index(['CtryName', 'CapacityMW'])[hourly_cols].reset_index()\n",
    "    hourly_profiles[tech] = data_MSR_hourlyprofile.groupby('CtryName').apply(weighted_hourly_profile).reset_index()\n",
    "\n",
    "    # Saving data in good format for representative days analysis\n",
    "    date_index = pd.date_range(start='2023-01-01', periods=8760, freq='h')  # 2023 is a non-leap year\n",
    "\n",
    "    df_long = hourly_profiles[tech].melt(id_vars='CtryName', var_name='Hour', value_name='value')\n",
    "\n",
    "    # Convert 'H1', ..., 'H8760' to integer hour index\n",
    "    df_long['hour_index'] = df_long['Hour'].str.extract('H(\\d+)').astype(int) - 1  # zero-based index\n",
    "\n",
    "    df_long['timestamp'] = df_long['hour_index'].map(lambda i: date_index[i])\n",
    "\n",
    "    # Convert local time to UTC\n",
    "    df_long['CtryName'] = df_long['CtryName'].astype(str)  # just in case\n",
    "    df_long['timestamp_utc'] = df_long.apply(lambda row: convert_to_utc(row, country_timezones), axis=1)\n",
    "\n",
    "    # Create season, day and hours\n",
    "    df_long['season'] = df_long['timestamp_utc'].dt.month\n",
    "    df_long['day'] = df_long['timestamp_utc'].dt.day\n",
    "    df_long['hour'] = df_long['timestamp_utc'].dt.hour\n",
    "\n",
    "    # Step 5: Rename and index\n",
    "    df_long = df_long.rename(columns={'CtryName': 'zone'})\n",
    "    df_final = df_long.set_index(['zone', 'season', 'day', 'hour'])['value']\n",
    "    df_final = df_final.to_frame().rename(columns={'value': 2018}).sort_values(by=['season', 'day', 'hour'])\n",
    "\n",
    "    df_final.to_csv(os.path.join('output', f'data_SAPP_{tech}.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd073cd811ad0107",
   "metadata": {},
   "source": [
    "## Step 4 - Visualize the results\n",
    "Create heatmaps and monthly profile summaries so stakeholders can quickly compare wind and solar performance across countries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e85ccf296d81a",
   "metadata": {},
   "source": [
    "#### Make heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed90c3b51004c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:19:19.516318Z",
     "start_time": "2025-07-02T16:19:19.039520Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    make_heatmap(cf_lcoe_stats, tech, filename=os.path.join('output', f'heatmap_{tech}_annual_cf.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cba9a76d5ace2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T16:20:00.351776Z",
     "start_time": "2025-07-02T16:19:59.618509Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "for tech in ['wind', 'solar']:\n",
    "    make_monthly_heatmap(hourly_profiles, tech, filename=os.path.join('output', f'heatmap_{tech}_monthly_cf.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d094a0dce5c893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esmap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
